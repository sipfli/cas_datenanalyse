{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAS-DA-SA_Payment_Fraud_Detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakuronohana/cas_datenanalyse/blob/master/Semesterarbeit/CAS_DA_SA_Payment_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRcJtvy3IiFf",
        "colab_type": "text"
      },
      "source": [
        "<img \n",
        "src=\"https://www.ffhs.ch/templates/ffhs/img/logo@2x.png\" width=\"100\"> \n",
        "###DaAn, Data Analysis, MAS/CAS Web4B 2018, ZH1, FS19, Dr. Tödtli Beat###\n",
        "\n",
        "##*Semesterarbeit von Patrik Di Lena*##\n",
        "#Betrugserkennung Zahlungsverkehr#\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu2Lax6MMPh0",
        "colab_type": "text"
      },
      "source": [
        "##Ziel##\n",
        "Das Ziel dieser Semesterarbeit ist die Gegenüberstellung von Supervised und Unsupervised Lernverfahren mit Hilfe neuronaler Netzwerk Algorithmen. Dabei kommt  ein nicht gelabelter und ein gelabelter Datensatz aus einem Betrugserkennungssystem zum Einsatz. \n",
        "\n",
        "##Aufgabenstellung##\n",
        "###Erkennung von Betrugszahlungen###\n",
        "Mittels Unsupervised Learning sollen Betrugszahlungen aus einem nicht gelabelten Datensatz erkannt und die Effiktivität des vorhandenen Fraud-Detection Systems geprüft werden. In diesem Fall wird ein Autoencoder Neural Network mit Tensorflow aufgebaut. \n",
        "\n",
        "###Betrugsanfällige Risikogruppen###\n",
        "Mit Hilfe von Supervised Learning werden mögliche Risikogruppen ermittelt, welche im Visier von Betrügern stehen.  Auf Basis eines gelabelten Datensatzes  werden die Risikogruppen nach folgenden Merkmalen unterschieden:\n",
        "\n",
        "*\tGeschlecht\n",
        "*\tAlter\n",
        "*\tZivilstand\n",
        "*\tNationalität\n",
        "*\tKontosaldo\n",
        "*\tWohnort\n",
        "*\tRegion\n",
        "\n",
        "In diesem Fall wird der Deep Learning Algorithmus Convlutional Neural Network zum Einsatz kommen.\n",
        "\n",
        "##Datensatz##\n",
        "Die im Rahmen dieser Semesterarbeit verwendeten Daten entstammen, von ihrer Datenstruktur her, aus einem bereits eingesetzten nicht ML-basierten Betrugserkennungssystem. Die Datenwerte wurde zu Wahrung der datenschutzrechtlichen und bankengesetzlichen Aspekte mit Hilfe eines Python-Scripts künstlich erzeugt und beinhalten somit keine reale Zahlungs- oder Kunden-Informationen.   \n",
        "\n",
        "Datenselektion:\n",
        "\n",
        "- 20'800 synthetische Kunden (Vorname, Name, Strasse, Ort, Kanton, Sprachregion, Geschlecht, Alter, Zivilstand,  Nationalität, Kontonummer, Vertragsnummer, Rechtsform)\n",
        "\n",
        "- 60'000 synthetische Zahlungen (Transaktionsid, ,Erstellungdatum/Zeit, Empfängerkonto, Empfängerbank, Empfängerland, Währung, Betrag, Valuta Datum)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz_l4l9VX0jr",
        "colab_type": "text"
      },
      "source": [
        "#Erkennung von Betrugszahlungen# \n",
        "\n",
        "##Unsupervised Learning mit neuronalen Netzwerken##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPNBtxFmnQg7",
        "colab_type": "text"
      },
      "source": [
        "###Importieren der ungelabelten Fraud-Zahlungsdaten###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9kpR8RAjMzw",
        "colab_type": "code",
        "outputId": "f86cb6d1-4e14-49f9-d2ed-bd3d6f09f8d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Laden der 600000 nicht gelabelten Transaktionsdaten \n",
        "trx_data_url = 'https://raw.githubusercontent.com/sakuronohana/cas_datenanalyse/master/Semesterarbeit/Dataset/trx_data_ol.csv'\n",
        "\n",
        "trx_data_ol = pd.read_csv(trx_data_url, delimiter=';')\n",
        "trx_data_ol.head()\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        timestamp   paym_id   send_bc_nr  amount    rcv_bc_nr  \\\n",
              "0  01.01.18 08:00  10000010  CHBANK71XXX   15368  JOBANK40XXX   \n",
              "1  01.01.18 08:00  10000011  CHBANK71XXX   89137  STBANK68XXX   \n",
              "2  01.01.18 08:01  10000012  CHBANK71XXX   87673  XKBANK43XXX   \n",
              "3  01.01.18 08:01  10000013  CHBANK71XXX   55941  RSBANK72XXX   \n",
              "4  01.01.18 08:02  10000014  CHBANK71XXX   88173  LIBANK48XXX   \n",
              "\n",
              "                      rcv_bc_iban         rcv_bc_country rcv_bc_code  \\\n",
              "0  JO02SCBL1260000000018525836101              Jordanien          JO   \n",
              "1       ST23000200000289355710148  Sao Tome und Principe          ST   \n",
              "2            XK051301001002074155                 Kosovo          XK   \n",
              "3          RS35105008054113238018                Serbien          RS   \n",
              "4           LI0308800000022875748          Liechtenstein          LI   \n",
              "\n",
              "              rcv_iban     valuta_date  cust_vertrag_nr  \\\n",
              "0  JO40002096331755419  01.01.18 08:00            76311   \n",
              "1  ST68002492808312214  01.01.18 20:00            69891   \n",
              "2  XK43002422391264290  02.01.18 08:01            78573   \n",
              "3  RS72002873180573624  02.01.18 20:01            75443   \n",
              "4  LI48002899580343897  03.01.18 08:02            73167   \n",
              "\n",
              "           cust_konto_nr  cust_vname cust_nname  cust_plz     cust_ort  \\\n",
              "0  CH5300772672529640195      Martin      Bader      6020  Emmenbrücke   \n",
              "1  CH5300772670061796126  Margaretha       Fehr      9056         Gais   \n",
              "2  CH5300772500037725234      Daniel   Miéville      1253  Vandoeuvres   \n",
              "3  CH5300772732508635138      Andrea      Iseni      6026         Rain   \n",
              "4  CH5300772640237288398      Andrea     Pinana      6693      Broglio   \n",
              "\n",
              "  cust_kanton cust_sprachregion cust_auth_device  \n",
              "0          LU                de             mtan  \n",
              "1          AR                de             ptan  \n",
              "2          GE                fr             ptan  \n",
              "3          LU                de             mtan  \n",
              "4          TI                it             mtan  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>paym_id</th>\n",
              "      <th>send_bc_nr</th>\n",
              "      <th>amount</th>\n",
              "      <th>rcv_bc_nr</th>\n",
              "      <th>rcv_bc_iban</th>\n",
              "      <th>rcv_bc_country</th>\n",
              "      <th>rcv_bc_code</th>\n",
              "      <th>rcv_iban</th>\n",
              "      <th>valuta_date</th>\n",
              "      <th>cust_vertrag_nr</th>\n",
              "      <th>cust_konto_nr</th>\n",
              "      <th>cust_vname</th>\n",
              "      <th>cust_nname</th>\n",
              "      <th>cust_plz</th>\n",
              "      <th>cust_ort</th>\n",
              "      <th>cust_kanton</th>\n",
              "      <th>cust_sprachregion</th>\n",
              "      <th>cust_auth_device</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01.01.18 08:00</td>\n",
              "      <td>10000010</td>\n",
              "      <td>CHBANK71XXX</td>\n",
              "      <td>15368</td>\n",
              "      <td>JOBANK40XXX</td>\n",
              "      <td>JO02SCBL1260000000018525836101</td>\n",
              "      <td>Jordanien</td>\n",
              "      <td>JO</td>\n",
              "      <td>JO40002096331755419</td>\n",
              "      <td>01.01.18 08:00</td>\n",
              "      <td>76311</td>\n",
              "      <td>CH5300772672529640195</td>\n",
              "      <td>Martin</td>\n",
              "      <td>Bader</td>\n",
              "      <td>6020</td>\n",
              "      <td>Emmenbrücke</td>\n",
              "      <td>LU</td>\n",
              "      <td>de</td>\n",
              "      <td>mtan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01.01.18 08:00</td>\n",
              "      <td>10000011</td>\n",
              "      <td>CHBANK71XXX</td>\n",
              "      <td>89137</td>\n",
              "      <td>STBANK68XXX</td>\n",
              "      <td>ST23000200000289355710148</td>\n",
              "      <td>Sao Tome und Principe</td>\n",
              "      <td>ST</td>\n",
              "      <td>ST68002492808312214</td>\n",
              "      <td>01.01.18 20:00</td>\n",
              "      <td>69891</td>\n",
              "      <td>CH5300772670061796126</td>\n",
              "      <td>Margaretha</td>\n",
              "      <td>Fehr</td>\n",
              "      <td>9056</td>\n",
              "      <td>Gais</td>\n",
              "      <td>AR</td>\n",
              "      <td>de</td>\n",
              "      <td>ptan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01.01.18 08:01</td>\n",
              "      <td>10000012</td>\n",
              "      <td>CHBANK71XXX</td>\n",
              "      <td>87673</td>\n",
              "      <td>XKBANK43XXX</td>\n",
              "      <td>XK051301001002074155</td>\n",
              "      <td>Kosovo</td>\n",
              "      <td>XK</td>\n",
              "      <td>XK43002422391264290</td>\n",
              "      <td>02.01.18 08:01</td>\n",
              "      <td>78573</td>\n",
              "      <td>CH5300772500037725234</td>\n",
              "      <td>Daniel</td>\n",
              "      <td>Miéville</td>\n",
              "      <td>1253</td>\n",
              "      <td>Vandoeuvres</td>\n",
              "      <td>GE</td>\n",
              "      <td>fr</td>\n",
              "      <td>ptan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01.01.18 08:01</td>\n",
              "      <td>10000013</td>\n",
              "      <td>CHBANK71XXX</td>\n",
              "      <td>55941</td>\n",
              "      <td>RSBANK72XXX</td>\n",
              "      <td>RS35105008054113238018</td>\n",
              "      <td>Serbien</td>\n",
              "      <td>RS</td>\n",
              "      <td>RS72002873180573624</td>\n",
              "      <td>02.01.18 20:01</td>\n",
              "      <td>75443</td>\n",
              "      <td>CH5300772732508635138</td>\n",
              "      <td>Andrea</td>\n",
              "      <td>Iseni</td>\n",
              "      <td>6026</td>\n",
              "      <td>Rain</td>\n",
              "      <td>LU</td>\n",
              "      <td>de</td>\n",
              "      <td>mtan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01.01.18 08:02</td>\n",
              "      <td>10000014</td>\n",
              "      <td>CHBANK71XXX</td>\n",
              "      <td>88173</td>\n",
              "      <td>LIBANK48XXX</td>\n",
              "      <td>LI0308800000022875748</td>\n",
              "      <td>Liechtenstein</td>\n",
              "      <td>LI</td>\n",
              "      <td>LI48002899580343897</td>\n",
              "      <td>03.01.18 08:02</td>\n",
              "      <td>73167</td>\n",
              "      <td>CH5300772640237288398</td>\n",
              "      <td>Andrea</td>\n",
              "      <td>Pinana</td>\n",
              "      <td>6693</td>\n",
              "      <td>Broglio</td>\n",
              "      <td>TI</td>\n",
              "      <td>it</td>\n",
              "      <td>mtan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmODZafznm1I",
        "colab_type": "text"
      },
      "source": [
        "###Feature Engineering###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2GAbTbYoRZ6",
        "colab_type": "code",
        "outputId": "2815ed85-8ef6-417c-a7ee-872bcbae8c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "# Bestimmte Daten in das richtige Format konvertieren\n",
        "\n",
        "# timestamp in Datums-und Zeitformat umwandeln\n",
        "#trx_data_ol.timestamp = pd.to_datetime(trx_data_ol['timestamp'])\n",
        "#trx_data_ol.valuta_date = pd.to_datetime(trx_data_ol['valuta_date'])\n",
        "#Suche des Datensatzes nach Null-Werten\n",
        "trx_data_ol.isnull().values.sum()\n",
        "\n",
        "trx_data_ol = pd.DataFrame(trx_data_ol, columns=['paym_id','send_bc_nr','amount','rcv_bc_nr', \n",
        "                                                 'rcv_bc_iban','rcv_bc_country','rcv_bc_code','rcv_iban',\n",
        "                                                  'cust_vertrag_nr','cust_konto_nr','cust_vname',\n",
        "                                                  'cust_nname','cust_plz','cust_ort','cust_kanton','cust_sprachregion',\n",
        "                                                  'cust_auth_device'])\n",
        "                                    \n",
        "\n",
        "trx_data_ol.dtypes\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "paym_id               int64\n",
              "send_bc_nr           object\n",
              "amount                int64\n",
              "rcv_bc_nr            object\n",
              "rcv_bc_iban          object\n",
              "rcv_bc_country       object\n",
              "rcv_bc_code          object\n",
              "rcv_iban             object\n",
              "cust_vertrag_nr       int64\n",
              "cust_konto_nr        object\n",
              "cust_vname           object\n",
              "cust_nname           object\n",
              "cust_plz              int64\n",
              "cust_ort             object\n",
              "cust_kanton          object\n",
              "cust_sprachregion    object\n",
              "cust_auth_device     object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POjMMOv1eaOg",
        "colab_type": "text"
      },
      "source": [
        "**Encoding kategorische Werte in nummerische Werte**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3jR2c3xCKGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Encoding Daten mit Dtype Object in nummerische Werte\n",
        "#trx_data_ol = pd.get_dummies(trx_data_ol, prefix_sep='_', drop_first=True)\n",
        "trx_data_ol = pd.get_dummies(trx_data_ol, columns=['paym_id','send_bc_nr','amount','rcv_bc_nr', \n",
        "                                                 'rcv_bc_iban','rcv_bc_country','rcv_bc_code','rcv_iban',\n",
        "                                                  'cust_vertrag_nr','cust_konto_nr','cust_vname',\n",
        "                                                  'cust_nname','cust_plz','cust_ort','cust_kanton','cust_sprachregion',\n",
        "                                                  'cust_auth_device'], 'paym_id','send_bc_nr','amount','rcv_bc_nr',dtype=float ,drop_first=True)\n",
        "trx_data_ol.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL0rWmtRXZDl",
        "colab_type": "code",
        "outputId": "ede27e33-be61-4932-dcaf-866acb6374e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "trx_data_ol.shape\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 86025)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOpc1G2kPtNB",
        "colab_type": "text"
      },
      "source": [
        "**Datensatz in Trainings- und Testingdatensatz aufteilen**\n",
        "\n",
        "Da wir über einen relative grosses Datenset verfügen können wir eine klassisches Spliting der Daten durchführen d.h. 80% (48'000)/20% (12'000) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bZxuuhWRook",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a7b28bac-b1fa-428d-edfb-37060c17f1be"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "tdo_train, tdo_test = train_test_split(trx_data_ol,test_size=0.2, random_state = 70)\n",
        "\n",
        "print ('Grösse Trainingsdatesatz (Shape) = ', tdo_train.shape)\n",
        "print ('Grösse Testdatensatz (Shape) =', tdo_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grösse Trainingsdatesatz (Shape) =  (48000, 86025)\n",
            "Grösse Testdatensatz (Shape) = (12000, 86025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wbzV5hWsyLo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8bbb1fff-8b5f-4498-b146-b161b4500fe9"
      },
      "source": [
        "#Erstellung eines kleines Trainingsdatensets für die Überprüfung \n",
        "#der NN Funktionalität\n",
        "\n",
        "tdo_small_train = tdo_train.sample(frac=0.1)\n",
        "tdo_small_test = tdo_small_train.sample(frac=0.2)\n",
        "print (tdo_small_train.shape)\n",
        "print (tdo_small_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4800, 86025)\n",
            "(960, 86025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFc3cqUKZOMF",
        "colab_type": "text"
      },
      "source": [
        "###Modell Training###\n",
        "\n",
        "Nachfolgenden werden wir ein neuronales Netzwerk definieren und dieses mit den oben bearbeiteten Daten trainieren.\n",
        "\n",
        "Für den Aufbau des neuronalen Netzwerks werden ich die Machine Learning Library **TensorFlow** von Google verwenden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfTD7txqbgiY",
        "colab_type": "text"
      },
      "source": [
        "**TensorFlow laden und Hyperparameter definieren**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s10dtH9h-VLv",
        "colab_type": "text"
      },
      "source": [
        "https://www.datascience.com/blog/fraud-detection-with-tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4SccBCDA1qG",
        "colab_type": "code",
        "outputId": "f30fc41e-cde4-4663-f174-1257d0e71794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# import packages\n",
        "# matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
        "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from pylab import rcParams\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras import regularizers\n",
        "'''\n",
        "#set random seed and percentage of test data\n",
        "RANDOM_SEED = 314 #used to help randomly select the data points\n",
        "TEST_PCT = 0.2 # 20% of the data\n",
        "\n",
        "#set up graphic style in this case I am using the color scheme from xkcd.com\n",
        "rcParams['figure.figsize'] = 14, 8.7 # Golden Mean\n",
        "LABELS = [\"Normal\",\"Fraud\"]\n",
        "col_list = [\"cerulean\",\"scarlet\"]# https://xkcd.com/color/rgb/\n",
        "sns.set(style='white', font_scale=1.75, palette=sns.xkcd_palette(col_list))\n",
        "'''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#set random seed and percentage of test data\\nRANDOM_SEED = 314 #used to help randomly select the data points\\nTEST_PCT = 0.2 # 20% of the data\\n\\n#set up graphic style in this case I am using the color scheme from xkcd.com\\nrcParams[\\'figure.figsize\\'] = 14, 8.7 # Golden Mean\\nLABELS = [\"Normal\",\"Fraud\"]\\ncol_list = [\"cerulean\",\"scarlet\"]# https://xkcd.com/color/rgb/\\nsns.set(style=\\'white\\', font_scale=1.75, palette=sns.xkcd_palette(col_list))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eozbqvhW-W7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_epoch = 100\n",
        "batch_size = 128\n",
        "input_dim = tdo_small_train.shape[1] #num of columns, 30\n",
        "encoding_dim = 14\n",
        "hidden_dim = int(encoding_dim / 2) #i.e. 7\n",
        "learning_rate = 1e-7\n",
        "\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
        "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
        "decoder = Dense(hidden_dim, activation='tanh')(encoder)\n",
        "decoder = Dense(input_dim, activation='relu')(decoder)\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwYkBXu1DQJB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3509
        },
        "outputId": "558234e3-7fc2-4e2b-bcbd-ed3495f3d334"
      },
      "source": [
        "autoencoder.compile(metrics=['accuracy'],\n",
        "                    loss='mean_squared_error',\n",
        "                    optimizer='adam')\n",
        "\n",
        "cp = ModelCheckpoint(filepath=\"autoencoder_fraud.h5\",\n",
        "                               save_best_only=True,\n",
        "                               verbose=0)\n",
        "\n",
        "tb = TensorBoard(log_dir='./logs',\n",
        "                histogram_freq=0,\n",
        "                write_graph=True,\n",
        "                write_images=True)\n",
        "\n",
        "history = autoencoder.fit(tdo_small_train,tdo_small_train,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(tdo_small_test, tdo_small_test),\n",
        "                    verbose=1,\n",
        "                    callbacks=[cp, tb]).history"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4800 samples, validate on 960 samples\n",
            "Epoch 1/100\n",
            "4800/4800 [==============================] - 275s 57ms/step - loss: 1169507713.7067 - acc: 0.0000e+00 - val_loss: 1169540420.2667 - val_acc: 0.0000e+00\n",
            "Epoch 2/100\n",
            "4800/4800 [==============================] - 274s 57ms/step - loss: 1169507635.2000 - acc: 0.0000e+00 - val_loss: 1169540164.2667 - val_acc: 0.0000e+00\n",
            "Epoch 3/100\n",
            "4800/4800 [==============================] - 273s 57ms/step - loss: 1169507467.9467 - acc: 0.0000e+00 - val_loss: 1169540164.2667 - val_acc: 0.0000e+00\n",
            "Epoch 4/100\n",
            "4800/4800 [==============================] - 272s 57ms/step - loss: 1169507478.1867 - acc: 0.9467 - val_loss: 1169540164.2667 - val_acc: 1.0000\n",
            "Epoch 5/100\n",
            "4800/4800 [==============================] - 270s 56ms/step - loss: 1169507326.2933 - acc: 0.1867 - val_loss: 1169539976.5333 - val_acc: 1.0000\n",
            "Epoch 6/100\n",
            "4800/4800 [==============================] - 270s 56ms/step - loss: 1169507256.3200 - acc: 1.0000 - val_loss: 1169539976.5333 - val_acc: 1.0000\n",
            "Epoch 7/100\n",
            "4800/4800 [==============================] - 267s 56ms/step - loss: 1169507252.9067 - acc: 0.2933 - val_loss: 1169539976.5333 - val_acc: 0.0000e+00\n",
            "Epoch 8/100\n",
            "4800/4800 [==============================] - 274s 57ms/step - loss: 1169507078.8267 - acc: 0.9733 - val_loss: 1169539686.4000 - val_acc: 1.0000\n",
            "Epoch 9/100\n",
            "4800/4800 [==============================] - 268s 56ms/step - loss: 1169506990.0800 - acc: 0.8267 - val_loss: 1169539686.4000 - val_acc: 0.0000e+00\n",
            "Epoch 10/100\n",
            "4800/4800 [==============================] - 277s 58ms/step - loss: 1169507013.9733 - acc: 0.0000e+00 - val_loss: 1169539686.4000 - val_acc: 0.0000e+00\n",
            "Epoch 11/100\n",
            "4800/4800 [==============================] - 277s 58ms/step - loss: 1169506897.9200 - acc: 0.4000 - val_loss: 1169539464.5333 - val_acc: 0.0000e+00\n",
            "Epoch 12/100\n",
            "4800/4800 [==============================] - 269s 56ms/step - loss: 1169506756.2667 - acc: 0.8133 - val_loss: 1169539464.5333 - val_acc: 1.0000\n",
            "Epoch 13/100\n",
            "4800/4800 [==============================] - 269s 56ms/step - loss: 1169506788.6933 - acc: 0.9467 - val_loss: 1169539447.4667 - val_acc: 1.0000\n",
            "Epoch 14/100\n",
            "4800/4800 [==============================] - 274s 57ms/step - loss: 1169506681.1733 - acc: 0.7867 - val_loss: 1169539259.7333 - val_acc: 1.0000\n",
            "Epoch 15/100\n",
            "4800/4800 [==============================] - 274s 57ms/step - loss: 1169506539.5200 - acc: 0.6533 - val_loss: 1169539259.7333 - val_acc: 1.0000\n",
            "Epoch 16/100\n",
            "4800/4800 [==============================] - 285s 59ms/step - loss: 1169506536.1067 - acc: 0.1067 - val_loss: 1169539259.7333 - val_acc: 0.0000e+00\n",
            "Epoch 17/100\n",
            "4800/4800 [==============================] - 273s 57ms/step - loss: 1169506464.4267 - acc: 0.0000e+00 - val_loss: 1169539020.8000 - val_acc: 0.0000e+00\n",
            "Epoch 18/100\n",
            "4800/4800 [==============================] - 276s 57ms/step - loss: 1169506317.6533 - acc: 0.0400 - val_loss: 1169539020.8000 - val_acc: 1.0000\n",
            "Epoch 19/100\n",
            "4800/4800 [==============================] - 277s 58ms/step - loss: 1169506309.1200 - acc: 0.1867 - val_loss: 1169539020.8000 - val_acc: 0.0000e+00\n",
            "Epoch 20/100\n",
            "4800/4800 [==============================] - 275s 57ms/step - loss: 1169506322.7733 - acc: 0.7600 - val_loss: 1169539020.8000 - val_acc: 1.0000\n",
            "Epoch 21/100\n",
            "4800/4800 [==============================] - 267s 56ms/step - loss: 1169506078.7200 - acc: 1.0000 - val_loss: 1169538773.3333 - val_acc: 1.0000\n",
            "Epoch 22/100\n",
            "4800/4800 [==============================] - 266s 55ms/step - loss: 1169506068.4800 - acc: 0.5733 - val_loss: 1169538773.3333 - val_acc: 1.0000\n",
            "Epoch 23/100\n",
            "4800/4800 [==============================] - 268s 56ms/step - loss: 1169506061.6533 - acc: 1.0000 - val_loss: 1169538773.3333 - val_acc: 1.0000\n",
            "Epoch 24/100\n",
            "4800/4800 [==============================] - 277s 58ms/step - loss: 1169505894.4000 - acc: 1.0000 - val_loss: 1169538534.4000 - val_acc: 1.0000\n",
            "Epoch 25/100\n",
            "4800/4800 [==============================] - 278s 58ms/step - loss: 1169505836.3733 - acc: 1.0000 - val_loss: 1169538534.4000 - val_acc: 1.0000\n",
            "Epoch 26/100\n",
            "4800/4800 [==============================] - 278s 58ms/step - loss: 1169505831.2533 - acc: 0.6667 - val_loss: 1169538534.4000 - val_acc: 0.0000e+00\n",
            "Epoch 27/100\n",
            "4800/4800 [==============================] - 275s 57ms/step - loss: 1169505713.4933 - acc: 0.9467 - val_loss: 1169538269.8667 - val_acc: 1.0000\n",
            "Epoch 28/100\n",
            "4800/4800 [==============================] - 274s 57ms/step - loss: 1169505600.8533 - acc: 1.0000 - val_loss: 1169538269.8667 - val_acc: 1.0000\n",
            "Epoch 29/100\n",
            "4800/4800 [==============================] - 271s 56ms/step - loss: 1169505590.6133 - acc: 1.0000 - val_loss: 1169538269.8667 - val_acc: 1.0000\n",
            "Epoch 30/100\n",
            "4800/4800 [==============================] - 271s 56ms/step - loss: 1169505570.1333 - acc: 1.0000 - val_loss: 1169538056.5333 - val_acc: 1.0000\n",
            "Epoch 31/100\n",
            "4800/4800 [==============================] - 281s 58ms/step - loss: 1169505368.7467 - acc: 0.8000 - val_loss: 1169538056.5333 - val_acc: 1.0000\n",
            "Epoch 32/100\n",
            "4800/4800 [==============================] - 268s 56ms/step - loss: 1169505358.5067 - acc: 1.0000 - val_loss: 1169538056.5333 - val_acc: 1.0000\n",
            "Epoch 33/100\n",
            "4800/4800 [==============================] - 273s 57ms/step - loss: 1169505344.8533 - acc: 1.0000 - val_loss: 1169538056.5333 - val_acc: 1.0000\n",
            "Epoch 34/100\n",
            "4800/4800 [==============================] - 269s 56ms/step - loss: 1169505141.7600 - acc: 1.0000 - val_loss: 1169537826.1333 - val_acc: 1.0000\n",
            "Epoch 35/100\n",
            "4800/4800 [==============================] - 270s 56ms/step - loss: 1169505126.4000 - acc: 1.0000 - val_loss: 1169537826.1333 - val_acc: 1.0000\n",
            "Epoch 36/100\n",
            "4800/4800 [==============================] - 276s 58ms/step - loss: 1169505133.2267 - acc: 1.0000 - val_loss: 1169537826.1333 - val_acc: 1.0000\n",
            "Epoch 37/100\n",
            "4800/4800 [==============================] - 281s 59ms/step - loss: 1169504965.9733 - acc: 1.0000 - val_loss: 1169537621.3333 - val_acc: 1.0000\n",
            "Epoch 38/100\n",
            "4800/4800 [==============================] - 272s 57ms/step - loss: 1169504897.7067 - acc: 1.0000 - val_loss: 1169537621.3333 - val_acc: 1.0000\n",
            "Epoch 39/100\n",
            "4800/4800 [==============================] - 269s 56ms/step - loss: 1169504896.0000 - acc: 1.0000 - val_loss: 1169537621.3333 - val_acc: 1.0000\n",
            "Epoch 40/100\n",
            "4800/4800 [==============================] - 269s 56ms/step - loss: 1169504805.5467 - acc: 1.0000 - val_loss: 1169537348.2667 - val_acc: 1.0000\n",
            "Epoch 41/100\n",
            "4800/4800 [==============================] - 275s 57ms/step - loss: 1169504651.9467 - acc: 1.0000 - val_loss: 1169537348.2667 - val_acc: 1.0000\n",
            "Epoch 42/100\n",
            "4800/4800 [==============================] - 282s 59ms/step - loss: 1169504650.2400 - acc: 1.0000 - val_loss: 1169537348.2667 - val_acc: 1.0000\n",
            "Epoch 43/100\n",
            "4800/4800 [==============================] - 277s 58ms/step - loss: 1169504633.1733 - acc: 1.0000 - val_loss: 1169537143.4667 - val_acc: 1.0000\n",
            "Epoch 44/100\n",
            "4800/4800 [==============================] - 278s 58ms/step - loss: 1169504433.4933 - acc: 1.0000 - val_loss: 1169537143.4667 - val_acc: 1.0000\n",
            "Epoch 45/100\n",
            "4800/4800 [==============================] - 271s 56ms/step - loss: 1169504416.4267 - acc: 1.0000 - val_loss: 1169537143.4667 - val_acc: 1.0000\n",
            "Epoch 46/100\n",
            "4800/4800 [==============================] - 265s 55ms/step - loss: 1169504442.0267 - acc: 1.0000 - val_loss: 1169537143.4667 - val_acc: 1.0000\n",
            "Epoch 47/100\n",
            "4800/4800 [==============================] - 273s 57ms/step - loss: 1169504216.7467 - acc: 1.0000 - val_loss: 1169536921.6000 - val_acc: 1.0000\n",
            "Epoch 48/100\n",
            "4800/4800 [==============================] - 275s 57ms/step - loss: 1169504168.9600 - acc: 1.0000 - val_loss: 1169536921.6000 - val_acc: 1.0000\n",
            "Epoch 49/100\n",
            "4800/4800 [==============================] - 273s 57ms/step - loss: 1169504184.3200 - acc: 1.0000 - val_loss: 1169536921.6000 - val_acc: 1.0000\n",
            "Epoch 50/100\n",
            "4800/4800 [==============================] - 278s 58ms/step - loss: 1169504037.5467 - acc: 1.0000 - val_loss: 1169536648.5333 - val_acc: 1.0000\n",
            "Epoch 51/100\n",
            "4800/4800 [==============================] - 326s 68ms/step - loss: 1169503948.8000 - acc: 1.0000 - val_loss: 1169536648.5333 - val_acc: 1.0000\n",
            "Epoch 52/100\n",
            "4800/4800 [==============================] - 296s 62ms/step - loss: 1169503931.7333 - acc: 1.0000 - val_loss: 1169536648.5333 - val_acc: 1.0000\n",
            "Epoch 53/100\n",
            "4800/4800 [==============================] - 292s 61ms/step - loss: 1169503878.8267 - acc: 1.0000 - val_loss: 1169536426.6667 - val_acc: 1.0000\n",
            "Epoch 54/100\n",
            "4800/4800 [==============================] - 295s 61ms/step - loss: 1169503716.6933 - acc: 1.0000 - val_loss: 1169536426.6667 - val_acc: 1.0000\n",
            "Epoch 55/100\n",
            "4800/4800 [==============================] - 279s 58ms/step - loss: 1169503709.8667 - acc: 1.0000 - val_loss: 1169536426.6667 - val_acc: 1.0000\n",
            "Epoch 56/100\n",
            "4800/4800 [==============================] - 273s 57ms/step - loss: 1169503718.4000 - acc: 1.0000 - val_loss: 1169536187.7333 - val_acc: 1.0000\n",
            "Epoch 57/100\n",
            "4800/4800 [==============================] - 285s 59ms/step - loss: 1169503493.1200 - acc: 1.0000 - val_loss: 1169536187.7333 - val_acc: 1.0000\n",
            "Epoch 58/100\n",
            "4800/4800 [==============================] - 270s 56ms/step - loss: 1169503488.0000 - acc: 1.0000 - val_loss: 1169536187.7333 - val_acc: 1.0000\n",
            "Epoch 59/100\n",
            "4800/4800 [==============================] - 276s 58ms/step - loss: 1169503498.2400 - acc: 1.0000 - val_loss: 1169536187.7333 - val_acc: 1.0000\n",
            "Epoch 60/100\n",
            "4800/4800 [==============================] - 271s 57ms/step - loss: 1169503313.9200 - acc: 1.0000 - val_loss: 1169535957.3333 - val_acc: 1.0000\n",
            "Epoch 61/100\n",
            "4800/4800 [==============================] - 277s 58ms/step - loss: 1169503252.4800 - acc: 1.0000 - val_loss: 1169535957.3333 - val_acc: 1.0000\n",
            "Epoch 62/100\n",
            "4800/4800 [==============================] - 272s 57ms/step - loss: 1169503242.2400 - acc: 1.0000 - val_loss: 1169535957.3333 - val_acc: 1.0000\n",
            "Epoch 63/100\n",
            "4800/4800 [==============================] - 274s 57ms/step - loss: 1169503143.2533 - acc: 1.0000 - val_loss: 1169535718.4000 - val_acc: 1.0000\n",
            "Epoch 64/100\n",
            "4800/4800 [==============================] - 278s 58ms/step - loss: 1169503020.3733 - acc: 1.0000 - val_loss: 1169535718.4000 - val_acc: 1.0000\n",
            "Epoch 65/100\n",
            "4800/4800 [==============================] - 315s 66ms/step - loss: 1169503008.4267 - acc: 1.0000 - val_loss: 1169535718.4000 - val_acc: 1.0000\n",
            "Epoch 66/100\n",
            "4800/4800 [==============================] - 296s 62ms/step - loss: 1169502981.1200 - acc: 1.0000 - val_loss: 1169535462.4000 - val_acc: 1.0000\n",
            "Epoch 67/100\n",
            "4800/4800 [==============================] - 281s 59ms/step - loss: 1169502764.3733 - acc: 1.0000 - val_loss: 1169535462.4000 - val_acc: 1.0000\n",
            "Epoch 68/100\n",
            "4800/4800 [==============================] - 272s 57ms/step - loss: 1169502767.7867 - acc: 1.0000 - val_loss: 1169535462.4000 - val_acc: 1.0000\n",
            "Epoch 69/100\n",
            "4800/4800 [==============================] - 285s 59ms/step - loss: 1169502781.4400 - acc: 1.0000 - val_loss: 1169535462.4000 - val_acc: 1.0000\n",
            "Epoch 70/100\n",
            "4800/4800 [==============================] - 277s 58ms/step - loss: 1169502585.1733 - acc: 1.0000 - val_loss: 1169535283.2000 - val_acc: 1.0000\n",
            "Epoch 71/100\n",
            "4800/4800 [==============================] - 274s 57ms/step - loss: 1169502540.8000 - acc: 1.0000 - val_loss: 1169535283.2000 - val_acc: 1.0000\n",
            "Epoch 72/100\n",
            "4800/4800 [==============================] - 272s 57ms/step - loss: 1169502532.2667 - acc: 1.0000 - val_loss: 1169535283.2000 - val_acc: 1.0000\n",
            "Epoch 73/100\n",
            "4800/4800 [==============================] - 273s 57ms/step - loss: 1169502397.4400 - acc: 1.0000 - val_loss: 1169535010.1333 - val_acc: 1.0000\n",
            "Epoch 74/100\n",
            "4800/4800 [==============================] - 276s 57ms/step - loss: 1169502296.7467 - acc: 1.0000 - val_loss: 1169535010.1333 - val_acc: 1.0000\n",
            "Epoch 75/100\n",
            "4800/4800 [==============================] - 278s 58ms/step - loss: 1169502312.1067 - acc: 1.0000 - val_loss: 1169534993.0667 - val_acc: 1.0000\n",
            "Epoch 76/100\n",
            "4800/4800 [==============================] - 295s 61ms/step - loss: 1169502211.4133 - acc: 1.0000 - val_loss: 1169534737.0667 - val_acc: 1.0000\n",
            "Epoch 77/100\n",
            "4800/4800 [==============================] - 272s 57ms/step - loss: 1169502071.4667 - acc: 1.0000 - val_loss: 1169534737.0667 - val_acc: 1.0000\n",
            "Epoch 78/100\n",
            "4800/4800 [==============================] - 294s 61ms/step - loss: 1169502057.8133 - acc: 1.0000 - val_loss: 1169534737.0667 - val_acc: 1.0000\n",
            "Epoch 79/100\n",
            "4800/4800 [==============================] - 273s 57ms/step - loss: 1169502074.8800 - acc: 1.0000 - val_loss: 1169534566.4000 - val_acc: 1.0000\n",
            "Epoch 80/100\n",
            "4800/4800 [==============================] - 274s 57ms/step - loss: 1169501832.5333 - acc: 1.0000 - val_loss: 1169534566.4000 - val_acc: 1.0000\n",
            "Epoch 81/100\n",
            "4800/4800 [==============================] - 274s 57ms/step - loss: 1169501839.3600 - acc: 1.0000 - val_loss: 1169534566.4000 - val_acc: 1.0000\n",
            "Epoch 82/100\n",
            "4800/4800 [==============================] - 287s 60ms/step - loss: 1169501825.7067 - acc: 1.0000 - val_loss: 1169534566.4000 - val_acc: 1.0000\n",
            "Epoch 83/100\n",
            "4800/4800 [==============================] - 278s 58ms/step - loss: 1169501660.1600 - acc: 1.0000 - val_loss: 1169534310.4000 - val_acc: 1.0000\n",
            "Epoch 84/100\n",
            "4800/4800 [==============================] - 279s 58ms/step - loss: 1169501603.8400 - acc: 1.0000 - val_loss: 1169534310.4000 - val_acc: 1.0000\n",
            "Epoch 85/100\n",
            "4800/4800 [==============================] - 274s 57ms/step - loss: 1169501610.6667 - acc: 1.0000 - val_loss: 1169534310.4000 - val_acc: 1.0000\n",
            "Epoch 86/100\n",
            "4800/4800 [==============================] - 275s 57ms/step - loss: 1169501480.9600 - acc: 1.0000 - val_loss: 1169534071.4667 - val_acc: 1.0000\n",
            "Epoch 87/100\n",
            "4800/4800 [==============================] - 301s 63ms/step - loss: 1169501385.3867 - acc: 1.0000 - val_loss: 1169534071.4667 - val_acc: 1.0000\n",
            "Epoch 88/100\n",
            "4800/4800 [==============================] - 271s 56ms/step - loss: 1169501358.0800 - acc: 1.0000 - val_loss: 1169534071.4667 - val_acc: 1.0000\n",
            "Epoch 89/100\n",
            "4800/4800 [==============================] - 281s 58ms/step - loss: 1169501323.9467 - acc: 1.0000 - val_loss: 1169533832.5333 - val_acc: 1.0000\n",
            "Epoch 90/100\n",
            "4800/4800 [==============================] - 292s 61ms/step - loss: 1169501125.9733 - acc: 1.0000 - val_loss: 1169533832.5333 - val_acc: 1.0000\n",
            "Epoch 91/100\n",
            "4800/4800 [==============================] - 277s 58ms/step - loss: 1169501149.8667 - acc: 1.0000 - val_loss: 1169533832.5333 - val_acc: 1.0000\n",
            "Epoch 92/100\n",
            "4800/4800 [==============================] - 280s 58ms/step - loss: 1169501129.3867 - acc: 1.0000 - val_loss: 1169533832.5333 - val_acc: 1.0000\n",
            "Epoch 93/100\n",
            "4800/4800 [==============================] - 279s 58ms/step - loss: 1169500916.0533 - acc: 1.0000 - val_loss: 1169533559.4667 - val_acc: 1.0000\n",
            "Epoch 94/100\n",
            "4800/4800 [==============================] - 271s 57ms/step - loss: 1169500907.5200 - acc: 1.0000 - val_loss: 1169533559.4667 - val_acc: 1.0000\n",
            "Epoch 95/100\n",
            "4800/4800 [==============================] - 281s 59ms/step - loss: 1169500910.9333 - acc: 1.0000 - val_loss: 1169533559.4667 - val_acc: 1.0000\n",
            "Epoch 96/100\n",
            "4800/4800 [==============================] - 275s 57ms/step - loss: 1169500757.3333 - acc: 1.0000 - val_loss: 1169533337.6000 - val_acc: 1.0000\n",
            "Epoch 97/100\n",
            "4800/4800 [==============================] - 276s 58ms/step - loss: 1169500658.3467 - acc: 1.0000 - val_loss: 1169533337.6000 - val_acc: 1.0000\n",
            "Epoch 98/100\n",
            "4800/4800 [==============================] - 277s 58ms/step - loss: 1169500642.9867 - acc: 1.0000 - val_loss: 1169533337.6000 - val_acc: 1.0000\n",
            "Epoch 99/100\n",
            "4800/4800 [==============================] - 279s 58ms/step - loss: 1169500586.6667 - acc: 1.0000 - val_loss: 1169533132.8000 - val_acc: 1.0000\n",
            "Epoch 100/100\n",
            "4800/4800 [==============================] - 286s 60ms/step - loss: 1169500405.7600 - acc: 1.0000 - val_loss: 1169533132.8000 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlGe3F7yEAwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder = load_model('autoencoder_fraud.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7Yspf-4EHt1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "53d42e2e-5cb3-489f-a5de-316005a2bd31"
      },
      "source": [
        "plt.plot(history['loss'], linewidth=2, label='Train')\n",
        "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "#plt.ylim(ymin=0.70,ymax=1)\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7I1cx12_2Gv",
        "colab_type": "text"
      },
      "source": [
        "#Ermittlung potenzieller Kundenrisikogruppen# \n",
        "##Supervised Learning mit neuronalen Netzwerken##\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b57Ggf-x-Iet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Laden der 600000 Transaktionsdaten \n",
        "trx_data_url = 'https://raw.githubusercontent.com/sakuronohana/cas_datenanalyse/master/Semesterarbeit/Dataset/trx_data_ml.csv'\n",
        "\n",
        "trx_data_ml = pd.read_csv(trx_data_url, delimiter=';')\n",
        "trx_data_ml.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4reOVH6SOoEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trx_data_ol.nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa3UBsB4PUcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trx_data.fraud_id.map(lambda x:1 if x>=1 else 0).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBv9TMCtc2s6",
        "colab_type": "text"
      },
      "source": [
        "**Erstellung des neuronalen Netzwerk-Modells**\n",
        "\n",
        "https://www.youtube.com/watch?v=BhpvH5DuVu8&list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v&index=46\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjPo4kEvdD8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "n_nodes_hl1 = 500\n",
        "n_nodes_hl2 = 500\n",
        "n_nodes_hl3 = 500\n",
        "\n",
        "n_classes = 10\n",
        "batch_size = 1000\n",
        "\n",
        "x = tf.placeholder('float',[None, 784])\n",
        "\n",
        "def neural_network_model(data):\n",
        "  hidden_1_layer = {'weights':tf.Variable(tf.random_normal([784,n_nodes_hl1])),\n",
        "                   'biases':tf.Variable(tf.random_normal(n_nodes_hl1))}\n",
        "  hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2,n_nodes_hl2])),\n",
        "                   'biases':tf.Variable(tf.random_normal(n_nodes_hl2))}\n",
        "  hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2,n_nodes_hl3])),\n",
        "                   'biases':tf.Variable(tf.random_normal(n_nodes_hl3))}\n",
        "  output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3,n_nodes_hl1])),\n",
        "                   'biases':tf.Variable(tf.random_normal(n_classes))}\n",
        "  \n",
        "  l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
        "  l1 = tf.nn.relu(l1)\n",
        "  \n",
        "  l2 = tf.add(tf.matmul(l1, hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
        "  l2 = tf.nn.relu(l2)\n",
        "  \n",
        "  l3 = tf.add(tf.matmul(l2, hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
        "  l3 = tf.nn.relu(l3)\n",
        "                 \n",
        "  output = tf.add(l3, output_layer['weights'])+ output_layer['biases']\n",
        "  \n",
        "  return output\n",
        "                  \n",
        "def train_neural_network(x):\n",
        "  prediction = neural_network_model(x)\n",
        "  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(prediction,y))\n",
        "  optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "  \n",
        "  hm_epochs = 10\n",
        "                  \n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.initialize_all_variables())\n",
        "    # Hier wird das Modell trainiert\n",
        "    for epoch in hm_epochs:\n",
        "        epoch_loss = 0\n",
        "        for _ in range(int(tdo_train.train.num_examples/batch_size)):\n",
        "            x = tdo_train.next_batch(batch_size)\n",
        "            _, c = sess.run([optimizer, cost], feed_dict = {x: x})\n",
        "            epoch_loss += c\n",
        "        print('Epoch', epoch, 'completed out of', hm_epochs, 'loss:', epoch_loss)\n",
        "                  \n",
        "    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
        "    print('Accuracy:', accuracy.eval({x:tdo_test}))\n",
        "    \n",
        "train_neural_network(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0Oh1LK53rMd",
        "colab_type": "text"
      },
      "source": [
        "##Datensatz analysieren##\n",
        "\n",
        "##Tipp: Plotting Learning Curves - Scikit !!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bzsG7nZ25CG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualisierung der Nummerischen Daten in dem Datensatz\n",
        "trx_data.hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-MjsTaU3kS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Suche nach den Korrelationen - Teil 1\n",
        "corr_matrix = trx_data.corr()\n",
        "print ('Korrelation zu Payment ID','\\n',corr_matrix['paym_id'].sort_values(ascending=False))\n",
        "print ('Korrelation zu Zahlungssumme','\\n',corr_matrix['amount'].sort_values(ascending=False))\n",
        "print ('Korrelation zu Kundenvertrag','\\n',corr_matrix['cust_vertrag_nr'].sort_values(ascending=False))\n",
        "print ('Korrelation zu Betrugsid','\\n',corr_matrix['fraud_id'].sort_values(ascending=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXoUuDUY3LpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bereinigung der Daten\n",
        "pd.to_datetime(trx_data['timestamp'])\n",
        "pd.to_datetime(trx_data['valuta_date'])\n",
        "np.where(np.isnan(trx_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6Vx75189gJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Datensatz in Trainings(80%)- und Testdatenset (20%) teilen\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_trx_data, test_trx_data = train_test_split(trx_data, test_size=0.2, random_state=42) \n",
        "train_trx_data.count(), test_trx_data.count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKYDanXj3Vm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dimensionsreduktion mit PCA\n",
        "from sklearn.decomposition import PCA # Import der PCA Funktion von Scikit Learn\n",
        "from sklearn import preprocessing # Die Preprocessing Funktion hilft uns die Daten zu skalieren bevor sie mit PCA verwendet werden."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}