{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lernkurven und Parameterplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voraussetzungen:   \n",
    "- Allgemeines Verständnis der Problemstellung beim supervised machine learning\n",
    "- Insbesondere, dass das Ziel Verallgemeinerung ist, und die Gefahr das Overfitting\n",
    "Die Lösung dieser Probleme besteht typischerweise in allgemeinen Prinzipien beim Vorgehen bei einem Klassifikationsproblem. Insbesondere muss fast immer zwingend: \n",
    "- jemand (Sie!) die Verantwortung übernehmen für ein korrektes Vorgehen beim Training. Diese Person wird auch Verallgemeinerungsaussagen gegenüber dem Auftragsteller verantworten müssen (z.B. dass das trainierte System auf neuen Daten mindestens eine Genauigkeit von 80% erreicht, o.ä.)\n",
    "- sofort ein Testset ausgesondert werden, welches nur zu einem Zweck benutzt werden darf: Zur abschliessenden Beurteilung der Genauigkeit eines einzigen Klassifikators. \n",
    "- Alle weitere Arbeit wird auf den restlichen Daten vorgenommen. Diese werden oft wieder in ein Trainings- und ein Validierungsset eingeteilt (oft im Verhältnis 80%/20% o.ä.). Der Klassifikator erhält die Trainingsdaten um zu lernen. Die Validierungsdaten werden benutzt, um die Genauigkeit des Klassifikators zu messen. \n",
    "- Je öfter Sie die Ergebnisse auf dem Validierungsset anschauen und danach (mit dieser Einsicht) einen neuer Klassifikator trainieren, umso schlechter wird die Verallgemeinerungsfähigkeit der aus dem Validierungsdatensatz gezogenen Schlüsse. Diese Art der \"Kontaminierung\" der Validierungsdaten soll auf dem Testset so strikt wie möglich verhindert werden. \n",
    "\n",
    "**In diesem Notebook betrachten wir Methoden, um Parameter eines Klassifikators zu setzen. Präziser: Um aus einem Hypothesenset einen geeigneten Kandidaten auszuwählen, der nur so viel von den Trainings- und Validierungsdaten lernt, wie er auf das Testset verallgemeinern kann.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "np.set_printoptions(precision=3)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lade die Daten\n",
    "#Die 'ID'-Spalte ist offensichtlich nur ein Index. Benutzen wir in ebenso:\n",
    "df=pd.read_csv('UCI_train.csv',index_col='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allgemeiner Überblick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verschaffen Sie sich mit Pandas einen Überblick über den Datensatz. \n",
    "- Erstellen Sie ein Trainings- und ein Testdatensatz, Xtrain und Xtest, sowie die zugehörigen Zielvariable ytrain und ytest. 20% der Daten sollen ins Testset. Arbeiten Sie nur ansonsten möglichst nur mit dem Trainingsset (siehe allerletzte Frage in diesem Notebook: Sie wollen Ihre Verallgemeinerungsfähigkeit nicht gefährden!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Parameterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameterplots sind Plots, welche eine Qualitätsgrösse (einen Score) eines Klassifikators gegen den Wert eines seiner Hyperparameter zeigt. Daran kann oft ein guter Wert abgelesen werden. Sinnvollerweise wird der Score cross-validiert bestimmt, d.h. mit einem Unsicherheits-Band versehen. Eine Vorlage dafür findet sich hier:\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n",
    "\n",
    "Aufgabe: Überprüfuen Sie, ob es sich lohnt, den nun folgenden Parameter-Plot um diese Unsicherheitsbänder zu verbessern. Können Sie die untenstehenden Zellen in eine for-Schleife verpacken?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_accuracy(knn,Xtrain,ytrain,scoresList,cvscoresList,cv=10):\n",
    "    knn.fit(Xtrain,ytrain)\n",
    "    scores=accuracy_score(knn.predict(Xtrain),ytrain)\n",
    "    print(\"training accuracy %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    cvscores=cross_val_score(knn,Xtrain,ytrain,cv=cv)\n",
    "    print(\"Cross-validation accuracy: %0.2f (+/- %0.2f)\" % (cvscores.mean(), cvscores.std() * 2))\n",
    "    scoresList.append(scores.mean())\n",
    "    cvscoresList.append(cvscores.mean())\n",
    "    return scoresList,cvscoresList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tal=[]\n",
    "cval=[]\n",
    "n_neighbors_list=[1,2,3,5,20,100,500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1e9a21dda7e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_neighbors_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "knn=sklearn.neighbors.KNeighborsClassifier(n_neighbors=n_neighbors_list[0])\n",
    "knn.fit(Xtrain,ytrain)\n",
    "tal,cval=evaluate_accuracy(knn,Xtrain,ytrain,tal,cval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c94c249c9a86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_neighbors_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "knn=sklearn.neighbors.KNeighborsClassifier(n_neighbors=n_neighbors_list[1])\n",
    "tal,cval=evaluate_accuracy(knn,Xtrain,ytrain,tal,cval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn=sklearn.neighbors.KNeighborsClassifier(n_neighbors=n_neighbors_list[2])\n",
    "tal,cval=evaluate_accuracy(knn,Xtrain,ytrain,tal,cval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn=sklearn.neighbors.KNeighborsClassifier(n_neighbors=n_neighbors_list[3])\n",
    "tal,cval=evaluate_accuracy(knn,Xtrain,ytrain,tal,cval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn=sklearn.neighbors.KNeighborsClassifier(n_neighbors=n_neighbors_list[4])\n",
    "tal,cval=evaluate_accuracy(knn,Xtrain,ytrain,tal,cval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn=sklearn.neighbors.KNeighborsClassifier(n_neighbors=n_neighbors_list[5])\n",
    "tal,cval=evaluate_accuracy(knn,Xtrain,ytrain,tal,cval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn=sklearn.neighbors.KNeighborsClassifier(n_neighbors=n_neighbors_list[6])\n",
    "tal,cval=evaluate_accuracy(knn,Xtrain,ytrain,tal,cval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax=plt.subplot(1,1,1)\n",
    "ax.plot(np.arange(len(tal)),tal,label='training score');\n",
    "ax.plot(np.arange(len(cval)),cval,label='mean cross-validation score');\n",
    "ax.set_xticklabels(n_neighbors_list)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bestes Resultat mit KNN:\n",
    "knn=sklearn.neighbors.KNeighborsClassifier(n_neighbors=20)\n",
    "tal,cval=evaluate_accuracy(knn,Xtrain,ytrain,tal,cval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Lernkurve für $k=20$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lernkurven zeigen, wie gut sich ein Klassifikator verbessert, wenn er mehr Daten zum trainieren erhält. Lernkurven sind Plots des Scores (z.B. der Genauigkeit) gegen die Grösse des Trainingssets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.logspace(-3, -1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn=sklearn.neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "plot_learning_curve(knn, \"Lernkurve\", Xtrain, ytrain, \n",
    "                    train_sizes=np.logspace(-8, -7, 20),ylim=(0.99,1.0), cv=-5, n_jobs=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es interessiert nun:  \n",
    "- Was bedeuten die Kurven? \n",
    "- Welchen Einfluss hat die Grösse des Trainingssets?\n",
    "- Wie verändern sie sich? Z.B. bei Veränderung von N (n_neighbors), dem Plot Range, dem Cross-Validation-Parameter etc.\n",
    "- Welche Ihrer Eigenschaften können Sie erklären? Sollte z.B. die Trainingskurve immer über der Testkurve liegen?\n",
    "- Was passiert bei wenn N=1 (Anzahl nearest neighbours)?  \n",
    "- Liegt ein Overfitting vor?\n",
    "\n",
    "** Finden Sie einen geeigneten Klassifikator. Deckt er sich mit dem im ParameterSearch gefundenen?**  \n",
    "** Welche Verallgemeinerungsgenauigkeit werden Sie Ihrem Auftraggeber versprechen?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v36",
   "language": "python",
   "name": "v36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
