{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAS-DA-SA_Payment_Fraud_Detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakuronohana/cas_datenanalyse/blob/master/Semesterarbeit/CAS_DA_SA_Payment_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRcJtvy3IiFf",
        "colab_type": "text"
      },
      "source": [
        "<img \n",
        "src=\"https://www.ffhs.ch/templates/ffhs/img/logo@2x.png\" width=\"100\"> \n",
        "###DaAn, Data Analysis, MAS/CAS Web4B 2018, ZH1, FS19, Dr. Tödtli Beat###\n",
        "\n",
        "##*Semesterarbeit von Patrik Di Lena*##\n",
        "#Betrugserkennung Zahlungsverkehr#\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu2Lax6MMPh0",
        "colab_type": "text"
      },
      "source": [
        "##Ziel##\n",
        "Das Ziel dieser Semesterarbeit ist die Gegenüberstellung von Supervised und Unsupervised Lernverfahren mit eine neuronalen Netzwerk Algorthmus. Dabei kommt  ein nicht gelabelter und ein gelabelter Datensatz aus einem Betrugserkennungssystem zum Einsatz. \n",
        "\n",
        "##Aufgabenstellung##\n",
        "###Erkennung von Betrugszahlungen###\n",
        "Mittels Unsupervised Learning sollen Betrugszahlungen aus einem nicht gelabelten Datensatz erkannt und die Effiktivität des vorhandenen Fraud-Detection Systems geprüft werden.\n",
        "\n",
        "###Betrugsanfällige Risikogruppen###\n",
        "Mit Hilfe von Supervised Learning werden mögliche Risikogruppen ermittelt, welche im Visier von Betrügern stehen.  Auf Basis eines gelabelten Datensatzes  werden die Risikogruppen nach folgenden Merkmalen unterschieden:\n",
        "\n",
        "*\tGeschlecht\n",
        "*\tAlter\n",
        "*\tZivilstand\n",
        "*\tNationalität\n",
        "*\tKontosaldo\n",
        "*\tWohnort\n",
        "*\tRegion\n",
        "\n",
        "##Datensatz##\n",
        "Die im Rahmen dieser Semesterarbeit verwendeten Daten entstammen, von ihrer Datenstruktur her, aus einem bereits eingesetzten nicht ML-basierten Betrugserkennungssystem. Die Datenwerte wurde zu Wahrung der datenschutzrechtlichen und bankengesetzlichen Aspekte mit Hilfe eines Python-Scripts künstlich erzeugt und beinhalten somit keine reale Zahlungs- oder Kunden-Informationen.   \n",
        "\n",
        "Datenselektion:\n",
        "\n",
        "- 20'800 synthetische Kunden (Vorname, Name, Strasse, Ort, Kanton, Sprachregion, Geschlecht, Alter, Zivilstand,  Nationalität, Kontonummer, Vertragsnummer, Rechtsform)\n",
        "\n",
        "- 60'000 synthetische Zahlungen (Transaktionsid, ,Erstellungdatum/Zeit, Empfängerkonto, Empfängerbank, Empfängerland, Währung, Betrag, Valuta Datum)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz_l4l9VX0jr",
        "colab_type": "text"
      },
      "source": [
        "#Erkennung von Betrugszahlungen# \n",
        "\n",
        "##Unsupervised Learning mit neuronalen Netzwerken##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPNBtxFmnQg7",
        "colab_type": "text"
      },
      "source": [
        "###Importieren der ungelabelten Fraud-Zahlungsdaten###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9kpR8RAjMzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Laden der 600000 nicht gelabelten Transaktionsdaten \n",
        "trx_data_url = 'https://raw.githubusercontent.com/sakuronohana/cas_datenanalyse/master/Semesterarbeit/Dataset/trx_data_ol.csv'\n",
        "\n",
        "trx_data_ol = pd.read_csv(trx_data_url, delimiter=';')\n",
        "trx_data_ol.head()\n",
        "trx_data_ol.nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmODZafznm1I",
        "colab_type": "text"
      },
      "source": [
        "###Feature Engineering###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjtsST2vuwFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Encoding Object Werte in Numeric Werte\n",
        "\n",
        "# DictVectorizer\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "# instantiate a Dictvectorizer object for X\n",
        "dv_X = DictVectorizer(sparse=False) \n",
        "# sparse = False makes the output is not a sparse matrix\n",
        "\n",
        "# convert trx_data_ol into dict\n",
        "trx_data_dict = trx_data_ol.to_dict(orient='records') # turn each row as key-value pairs\n",
        "\n",
        "# apply dv_X on X_dict\n",
        "X_encoded = dv_X.fit_transform(trx_data_dict)\n",
        "# show X_encoded\n",
        "X_encoded\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZQ_isr_xzgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Categorical boolean mask\n",
        "categorical_feature_mask = trx_data_ol.dtypes==object\n",
        "# filter categorical columns using mask and turn it into a list\n",
        "categorical_cols = trx_data_ol.columns[categorical_feature_mask].tolist()\n",
        "\n",
        "# import labelencoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# instantiate labelencoder object\n",
        "le = LabelEncoder()\n",
        "\n",
        "# apply le on categorical feature columns\n",
        "trx_data_ol[categorical_cols] = trx_data_ol[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
        "trx_data_ol[categorical_cols].head(10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7I1cx12_2Gv",
        "colab_type": "text"
      },
      "source": [
        "#Ermittlung potenzieller Kundenrisikogruppen# \n",
        "##Supervised Learning mit neuronalen Netzwerken##\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b57Ggf-x-Iet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Laden der 600000 Transaktionsdaten \n",
        "trx_data_url = 'https://raw.githubusercontent.com/sakuronohana/cas_datenanalyse/master/Semesterarbeit/Dataset/trx_data_ml.csv'\n",
        "\n",
        "trx_data_ml = pd.read_csv(trx_data_url, delimiter=';')\n",
        "trx_data_ml.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4reOVH6SOoEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trx_data_ol.nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa3UBsB4PUcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trx_data.fraud_id.map(lambda x:1 if x>=1 else 0).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0Oh1LK53rMd",
        "colab_type": "text"
      },
      "source": [
        "##Datensatz analysieren##\n",
        "\n",
        "##Tipp: Plotting Learning Curves - Scikit !!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bzsG7nZ25CG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualisierung der Nummerischen Daten in dem Datensatz\n",
        "trx_data.hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-MjsTaU3kS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Suche nach den Korrelationen - Teil 1\n",
        "corr_matrix = trx_data.corr()\n",
        "print ('Korrelation zu Payment ID','\\n',corr_matrix['paym_id'].sort_values(ascending=False))\n",
        "print ('Korrelation zu Zahlungssumme','\\n',corr_matrix['amount'].sort_values(ascending=False))\n",
        "print ('Korrelation zu Kundenvertrag','\\n',corr_matrix['cust_vertrag_nr'].sort_values(ascending=False))\n",
        "print ('Korrelation zu Betrugsid','\\n',corr_matrix['fraud_id'].sort_values(ascending=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXoUuDUY3LpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bereinigung der Daten\n",
        "pd.to_datetime(trx_data['timestamp'])\n",
        "pd.to_datetime(trx_data['valuta_date'])\n",
        "np.where(np.isnan(trx_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6Vx75189gJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Datensatz in Trainings(80%)- und Testdatenset (20%) teilen\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_trx_data, test_trx_data = train_test_split(trx_data, test_size=0.2, random_state=42) \n",
        "train_trx_data.count(), test_trx_data.count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKYDanXj3Vm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dimensionsreduktion mit PCA\n",
        "from sklearn.decomposition import PCA # Import der PCA Funktion von Scikit Learn\n",
        "from sklearn import preprocessing # Die Preprocessing Funktion hilft uns die Daten zu skalieren bevor sie mit PCA verwendet werden."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}