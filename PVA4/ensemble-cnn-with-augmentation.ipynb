{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "train_data = pd.read_csv('../input/train.csv',header=None)\n",
    "test_data = pd.read_csv('../input/test.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "78715e6a54e12a02a6779115a7df5dbc4bbdbecd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>746</th>\n",
       "      <th>747</th>\n",
       "      <th>748</th>\n",
       "      <th>749</th>\n",
       "      <th>750</th>\n",
       "      <th>751</th>\n",
       "      <th>752</th>\n",
       "      <th>753</th>\n",
       "      <th>754</th>\n",
       "      <th>755</th>\n",
       "      <th>756</th>\n",
       "      <th>757</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>768</th>\n",
       "      <th>769</th>\n",
       "      <th>770</th>\n",
       "      <th>771</th>\n",
       "      <th>772</th>\n",
       "      <th>773</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "      <th>785</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>67</td>\n",
       "      <td>178</td>\n",
       "      <td>203</td>\n",
       "      <td>131</td>\n",
       "      <td>179</td>\n",
       "      <td>82</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>77</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>255</td>\n",
       "      <td>251</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>251</td>\n",
       "      <td>255</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>255</td>\n",
       "      <td>251</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>221</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>84</td>\n",
       "      <td>80</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>122</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>115</td>\n",
       "      <td>114</td>\n",
       "      <td>96</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>136</td>\n",
       "      <td>183</td>\n",
       "      <td>170</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>176</td>\n",
       "      <td>226</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>236</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>189</td>\n",
       "      <td>57</td>\n",
       "      <td>211</td>\n",
       "      <td>252</td>\n",
       "      <td>234</td>\n",
       "      <td>168</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>90</td>\n",
       "      <td>99</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1    2    3    4    5    6   ...   779  780  781  782  783  784  785\n",
       "0    0   A    0    0    0    0    0 ...    19    4   30   11    8   77   13\n",
       "1    1   A  255  255  255  255  255 ...     0  153  255  251  255  255  255\n",
       "2    2   A    0    0    0    0    0 ...   117  117  117  115  114   96   19\n",
       "3    3   A    0    0    0    0    0 ...     0    3    0   24   90   99   28\n",
       "\n",
       "[4 rows x 786 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "bc6a4f5610618c35b5df3886380436de47e76e6f"
   },
   "outputs": [],
   "source": [
    "train_target = train_data[1]\n",
    "\n",
    "del train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "2581fb4e89fcd66abad377328e8b133468e90f10"
   },
   "outputs": [],
   "source": [
    "del train_data[0]\n",
    "del test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "80503ba7c01e3c4454aa4ab4681ab3e50eb13ab4"
   },
   "outputs": [],
   "source": [
    "train_data = train_data.values\n",
    "test_data = test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "4402edbbcdb7ab2cda2f0341cd4665db25aa2295"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "4a71b2de5fcc127c828628b1e4a767cc7b182459"
   },
   "outputs": [],
   "source": [
    "X_train = train_data.reshape(-1, 28, 28 , 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "5a9f0599a4f8e3c056af1253097c36b2f778cfb8"
   },
   "outputs": [],
   "source": [
    "X_test = test_data.reshape(-1, 28, 28 , 1).astype('float32')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "27d77be833f83a9925fa20f473f76d4390ecb807"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "286269409449e7fd28d9ff49c1a6477e62880075"
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "7d62492cf34cd6cb5cfe04a299a557d37a8c085c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "dc2c58f04d636a6d8f951d2b2bcd23dbe30a3209"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "train_target = enc.fit_transform(train_target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "1cba7d0fb7caf81b68a80bc400a791a3410d9bc2"
   },
   "outputs": [],
   "source": [
    "Y_train = to_categorical(train_target, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "443008a6485817fc698026e8a4b36cfa948c2caf"
   },
   "outputs": [],
   "source": [
    "# Split the train and the validation set for the fitting\n",
    "# X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=20182019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "3946a8d01c927c85b248c54a90bfb657b4065f03"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[25][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "c8908b4b11bca5355e244da51b0d0f08dbc51371"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "60e951c79a8efb6fcc254076f07cb2f548caf551"
   },
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "a1ce3ec016de30f4cbdae62f8e100f03fb80d0d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.layers import DepthwiseConv2D, Reshape, Activation\n",
    "\n",
    "nets = 20\n",
    "model = [0] *nets\n",
    "\n",
    "\n",
    "for j in range(nets):\n",
    "    model[j] = Sequential()\n",
    "\n",
    "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Dropout(0.35))\n",
    "\n",
    "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Dropout(0.4))\n",
    "\n",
    "    model[j].add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Flatten())\n",
    "    model[j].add(Dropout(0.4))\n",
    "    model[j].add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\n",
    "    model[j].compile(optimizer='adagrad', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "8c1894535205d883a45426f66ccecbe3e73ba817"
   },
   "outputs": [],
   "source": [
    "# LR Reduction Callback\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=0, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "02a92f609933a80a0be514ce3c0c4f9725daf81b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net : 1\n",
      "Epoch 1/30\n",
      "131/131 [==============================] - 10s 79ms/step - loss: 0.9666 - acc: 0.7029 - val_loss: 0.3640 - val_acc: 0.8985\n",
      "Epoch 2/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.5699 - acc: 0.8281 - val_loss: 0.2946 - val_acc: 0.9081\n",
      "Epoch 3/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.4949 - acc: 0.8536 - val_loss: 0.2728 - val_acc: 0.9167\n",
      "Epoch 4/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.4295 - acc: 0.8696 - val_loss: 0.2339 - val_acc: 0.9263\n",
      "Epoch 5/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.4048 - acc: 0.8809 - val_loss: 0.2160 - val_acc: 0.9370\n",
      "Epoch 6/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3592 - acc: 0.8865 - val_loss: 0.2253 - val_acc: 0.9359\n",
      "Epoch 7/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.3470 - acc: 0.8944 - val_loss: 0.2036 - val_acc: 0.9423\n",
      "Epoch 8/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3223 - acc: 0.9007 - val_loss: 0.1998 - val_acc: 0.9423\n",
      "Epoch 9/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3227 - acc: 0.9030 - val_loss: 0.2008 - val_acc: 0.9380\n",
      "Epoch 10/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3257 - acc: 0.9006 - val_loss: 0.2096 - val_acc: 0.9412\n",
      "Epoch 11/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2832 - acc: 0.9148 - val_loss: 0.1917 - val_acc: 0.9412\n",
      "Epoch 12/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2853 - acc: 0.9119 - val_loss: 0.1857 - val_acc: 0.9434\n",
      "Epoch 13/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2683 - acc: 0.9203 - val_loss: 0.2502 - val_acc: 0.9113\n",
      "Epoch 14/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2680 - acc: 0.9187 - val_loss: 0.1907 - val_acc: 0.9423\n",
      "Epoch 15/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2682 - acc: 0.9158 - val_loss: 0.1838 - val_acc: 0.9455\n",
      "Epoch 16/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2692 - acc: 0.9165 - val_loss: 0.1768 - val_acc: 0.9455\n",
      "Epoch 17/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2550 - acc: 0.9227 - val_loss: 0.1936 - val_acc: 0.9412\n",
      "Epoch 18/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2581 - acc: 0.9217 - val_loss: 0.1867 - val_acc: 0.9434\n",
      "Epoch 19/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2547 - acc: 0.9227 - val_loss: 0.1837 - val_acc: 0.9444\n",
      "Epoch 20/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2482 - acc: 0.9247 - val_loss: 0.1812 - val_acc: 0.9444\n",
      "Epoch 21/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2500 - acc: 0.9229 - val_loss: 0.1763 - val_acc: 0.9434\n",
      "Epoch 22/30\n",
      "131/131 [==============================] - 3s 20ms/step - loss: 0.2338 - acc: 0.9299 - val_loss: 0.1782 - val_acc: 0.9476\n",
      "Epoch 23/30\n",
      "131/131 [==============================] - 3s 22ms/step - loss: 0.2426 - acc: 0.9273 - val_loss: 0.1837 - val_acc: 0.9402\n",
      "Epoch 24/30\n",
      "131/131 [==============================] - 3s 21ms/step - loss: 0.2355 - acc: 0.9279 - val_loss: 0.1762 - val_acc: 0.9444\n",
      "Epoch 25/30\n",
      "131/131 [==============================] - 3s 21ms/step - loss: 0.2533 - acc: 0.9258 - val_loss: 0.1811 - val_acc: 0.9455\n",
      "Epoch 26/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2340 - acc: 0.9275 - val_loss: 0.1797 - val_acc: 0.9434\n",
      "Epoch 27/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2395 - acc: 0.9295 - val_loss: 0.1840 - val_acc: 0.9423\n",
      "Epoch 28/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2395 - acc: 0.9264 - val_loss: 0.1794 - val_acc: 0.9423\n",
      "Epoch 29/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2421 - acc: 0.9244 - val_loss: 0.1788 - val_acc: 0.9434\n",
      "Epoch 30/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2240 - acc: 0.9291 - val_loss: 0.1779 - val_acc: 0.9412\n",
      "CNN 1: Epochs=30, Train accuracy=0.92990, Validation accuracy=0.94765\n",
      "Net : 2\n",
      "Epoch 1/30\n",
      "131/131 [==============================] - 5s 40ms/step - loss: 1.0047 - acc: 0.6979 - val_loss: 0.5424 - val_acc: 0.8462\n",
      "Epoch 2/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.5580 - acc: 0.8354 - val_loss: 0.4002 - val_acc: 0.8707\n",
      "Epoch 3/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.4782 - acc: 0.8578 - val_loss: 0.2709 - val_acc: 0.9220\n",
      "Epoch 4/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.4310 - acc: 0.8710 - val_loss: 0.2744 - val_acc: 0.9124\n",
      "Epoch 5/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3914 - acc: 0.8831 - val_loss: 0.2480 - val_acc: 0.9295\n",
      "Epoch 6/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.3677 - acc: 0.8840 - val_loss: 0.2231 - val_acc: 0.9295\n",
      "Epoch 7/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.3441 - acc: 0.8973 - val_loss: 0.2163 - val_acc: 0.9327\n",
      "Epoch 8/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.3230 - acc: 0.9028 - val_loss: 0.2170 - val_acc: 0.9327\n",
      "Epoch 9/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3093 - acc: 0.9037 - val_loss: 0.2210 - val_acc: 0.9274\n",
      "Epoch 10/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3111 - acc: 0.9022 - val_loss: 0.2082 - val_acc: 0.9348\n",
      "Epoch 11/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2907 - acc: 0.9115 - val_loss: 0.2947 - val_acc: 0.8964\n",
      "Epoch 12/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2857 - acc: 0.9116 - val_loss: 0.1942 - val_acc: 0.9391\n",
      "Epoch 13/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2795 - acc: 0.9159 - val_loss: 0.1962 - val_acc: 0.9380\n",
      "Epoch 14/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2601 - acc: 0.9199 - val_loss: 0.1887 - val_acc: 0.9370\n",
      "Epoch 15/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2610 - acc: 0.9215 - val_loss: 0.2035 - val_acc: 0.9316\n",
      "Epoch 16/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2453 - acc: 0.9253 - val_loss: 0.1912 - val_acc: 0.9370\n",
      "Epoch 17/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2588 - acc: 0.9198 - val_loss: 0.5850 - val_acc: 0.8440\n",
      "Epoch 18/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2235 - acc: 0.9331 - val_loss: 0.1956 - val_acc: 0.9359\n",
      "Epoch 19/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2341 - acc: 0.9289 - val_loss: 0.1872 - val_acc: 0.9402\n",
      "Epoch 20/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2289 - acc: 0.9304 - val_loss: 0.1878 - val_acc: 0.9412\n",
      "Epoch 21/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2283 - acc: 0.9310 - val_loss: 0.1886 - val_acc: 0.9412\n",
      "Epoch 22/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2267 - acc: 0.9318 - val_loss: 0.1881 - val_acc: 0.9423\n",
      "Epoch 23/30\n",
      "131/131 [==============================] - 3s 21ms/step - loss: 0.2278 - acc: 0.9298 - val_loss: 0.1822 - val_acc: 0.9423\n",
      "Epoch 24/30\n",
      "131/131 [==============================] - 3s 22ms/step - loss: 0.2168 - acc: 0.9324 - val_loss: 0.1796 - val_acc: 0.9423\n",
      "Epoch 25/30\n",
      "131/131 [==============================] - 3s 21ms/step - loss: 0.2277 - acc: 0.9314 - val_loss: 0.1820 - val_acc: 0.9466\n",
      "Epoch 26/30\n",
      "131/131 [==============================] - 3s 21ms/step - loss: 0.2231 - acc: 0.9306 - val_loss: 0.1830 - val_acc: 0.9434\n",
      "Epoch 27/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2229 - acc: 0.9319 - val_loss: 0.1834 - val_acc: 0.9455\n",
      "Epoch 28/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2149 - acc: 0.9357 - val_loss: 0.1806 - val_acc: 0.9466\n",
      "Epoch 29/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2240 - acc: 0.9349 - val_loss: 0.1811 - val_acc: 0.9434\n",
      "Epoch 30/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2128 - acc: 0.9350 - val_loss: 0.1824 - val_acc: 0.9444\n",
      "CNN 2: Epochs=30, Train accuracy=0.93577, Validation accuracy=0.94658\n",
      "Net : 3\n",
      "Epoch 1/30\n",
      "131/131 [==============================] - 6s 43ms/step - loss: 0.9687 - acc: 0.7121 - val_loss: 0.3886 - val_acc: 0.9028\n",
      "Epoch 2/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.5639 - acc: 0.8313 - val_loss: 0.3129 - val_acc: 0.9092\n",
      "Epoch 3/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.4678 - acc: 0.8598 - val_loss: 0.2751 - val_acc: 0.9199\n",
      "Epoch 4/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.4026 - acc: 0.8762 - val_loss: 0.2649 - val_acc: 0.9220\n",
      "Epoch 5/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3953 - acc: 0.8803 - val_loss: 0.2469 - val_acc: 0.9209\n",
      "Epoch 6/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.3695 - acc: 0.8890 - val_loss: 0.2808 - val_acc: 0.9209\n",
      "Epoch 7/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3372 - acc: 0.9010 - val_loss: 0.2443 - val_acc: 0.9252\n",
      "Epoch 8/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3194 - acc: 0.9051 - val_loss: 0.2308 - val_acc: 0.9327\n",
      "Epoch 9/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3203 - acc: 0.9022 - val_loss: 0.2188 - val_acc: 0.9327\n",
      "Epoch 10/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2953 - acc: 0.9086 - val_loss: 0.2141 - val_acc: 0.9348\n",
      "Epoch 11/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2982 - acc: 0.9083 - val_loss: 0.1942 - val_acc: 0.9423\n",
      "Epoch 12/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2968 - acc: 0.9083 - val_loss: 0.2228 - val_acc: 0.9423\n",
      "Epoch 13/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2772 - acc: 0.9159 - val_loss: 0.2187 - val_acc: 0.9412\n",
      "Epoch 14/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2846 - acc: 0.9171 - val_loss: 0.1792 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2678 - acc: 0.9207 - val_loss: 0.1925 - val_acc: 0.9444\n",
      "Epoch 16/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2607 - acc: 0.9199 - val_loss: 0.1887 - val_acc: 0.9402\n",
      "Epoch 17/30\n",
      "131/131 [==============================] - 3s 21ms/step - loss: 0.2607 - acc: 0.9177 - val_loss: 0.1771 - val_acc: 0.9455\n",
      "Epoch 18/30\n",
      "131/131 [==============================] - 3s 21ms/step - loss: 0.2425 - acc: 0.9284 - val_loss: 0.1774 - val_acc: 0.9519\n",
      "Epoch 19/30\n",
      "131/131 [==============================] - 3s 22ms/step - loss: 0.2332 - acc: 0.9275 - val_loss: 0.1695 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "131/131 [==============================] - 3s 20ms/step - loss: 0.2345 - acc: 0.9287 - val_loss: 0.1735 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2324 - acc: 0.9271 - val_loss: 0.1758 - val_acc: 0.9509\n",
      "Epoch 22/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2189 - acc: 0.9317 - val_loss: 0.1704 - val_acc: 0.9519\n",
      "Epoch 23/30\n",
      "131/131 [==============================] - 3s 21ms/step - loss: 0.2267 - acc: 0.9302 - val_loss: 0.1696 - val_acc: 0.9498\n",
      "Epoch 24/30\n",
      "131/131 [==============================] - 3s 22ms/step - loss: 0.2282 - acc: 0.9283 - val_loss: 0.1692 - val_acc: 0.9530\n",
      "Epoch 25/30\n",
      "131/131 [==============================] - 3s 22ms/step - loss: 0.2214 - acc: 0.9296 - val_loss: 0.1704 - val_acc: 0.9530\n",
      "Epoch 26/30\n",
      "131/131 [==============================] - 3s 21ms/step - loss: 0.2255 - acc: 0.9283 - val_loss: 0.1679 - val_acc: 0.9519\n",
      "Epoch 27/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2283 - acc: 0.9299 - val_loss: 0.1687 - val_acc: 0.9509\n",
      "Epoch 28/30\n",
      "131/131 [==============================] - 3s 19ms/step - loss: 0.2138 - acc: 0.9320 - val_loss: 0.1689 - val_acc: 0.9541\n",
      "Epoch 29/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2243 - acc: 0.9319 - val_loss: 0.1672 - val_acc: 0.9509\n",
      "Epoch 30/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2190 - acc: 0.9336 - val_loss: 0.1681 - val_acc: 0.9519\n",
      "CNN 3: Epochs=30, Train accuracy=0.93373, Validation accuracy=0.95406\n",
      "Net : 4\n",
      "Epoch 1/30\n",
      "131/131 [==============================] - 6s 44ms/step - loss: 1.0141 - acc: 0.6917 - val_loss: 0.4045 - val_acc: 0.8889\n",
      "Epoch 2/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.5833 - acc: 0.8260 - val_loss: 0.3048 - val_acc: 0.9038\n",
      "Epoch 3/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.4690 - acc: 0.8599 - val_loss: 0.3769 - val_acc: 0.8686\n",
      "Epoch 4/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.4307 - acc: 0.8696 - val_loss: 0.2767 - val_acc: 0.9220\n",
      "Epoch 5/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3980 - acc: 0.8801 - val_loss: 0.2294 - val_acc: 0.9284\n",
      "Epoch 6/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3556 - acc: 0.8961 - val_loss: 0.2357 - val_acc: 0.9284\n",
      "Epoch 7/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3507 - acc: 0.8954 - val_loss: 0.2317 - val_acc: 0.9338\n",
      "Epoch 8/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.3228 - acc: 0.8991 - val_loss: 0.2250 - val_acc: 0.9295\n",
      "Epoch 9/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3016 - acc: 0.9076 - val_loss: 0.2219 - val_acc: 0.9306\n",
      "Epoch 10/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3196 - acc: 0.9031 - val_loss: 0.2048 - val_acc: 0.9316\n",
      "Epoch 11/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2920 - acc: 0.9095 - val_loss: 0.2046 - val_acc: 0.9348\n",
      "Epoch 12/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2856 - acc: 0.9144 - val_loss: 0.2019 - val_acc: 0.9359\n",
      "Epoch 13/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2735 - acc: 0.9159 - val_loss: 0.1973 - val_acc: 0.9338\n",
      "Epoch 14/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2699 - acc: 0.9188 - val_loss: 0.1937 - val_acc: 0.9370\n",
      "Epoch 15/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2651 - acc: 0.9173 - val_loss: 0.1926 - val_acc: 0.9348\n",
      "Epoch 16/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2575 - acc: 0.9205 - val_loss: 0.1952 - val_acc: 0.9391\n",
      "Epoch 17/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2497 - acc: 0.9214 - val_loss: 0.1944 - val_acc: 0.9359\n",
      "Epoch 18/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2584 - acc: 0.9200 - val_loss: 0.1881 - val_acc: 0.9391\n",
      "Epoch 19/30\n",
      "131/131 [==============================] - 3s 19ms/step - loss: 0.2308 - acc: 0.9287 - val_loss: 0.1910 - val_acc: 0.9391\n",
      "Epoch 20/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2503 - acc: 0.9240 - val_loss: 0.1894 - val_acc: 0.9391\n",
      "Epoch 21/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2337 - acc: 0.9277 - val_loss: 0.1840 - val_acc: 0.9402\n",
      "Epoch 22/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2361 - acc: 0.9258 - val_loss: 0.1909 - val_acc: 0.9391\n",
      "Epoch 23/30\n",
      "131/131 [==============================] - 3s 20ms/step - loss: 0.2319 - acc: 0.9286 - val_loss: 0.1832 - val_acc: 0.9391\n",
      "Epoch 24/30\n",
      "131/131 [==============================] - 3s 22ms/step - loss: 0.2428 - acc: 0.9266 - val_loss: 0.1858 - val_acc: 0.9402\n",
      "Epoch 25/30\n",
      "131/131 [==============================] - 3s 21ms/step - loss: 0.2293 - acc: 0.9286 - val_loss: 0.1866 - val_acc: 0.9380\n",
      "Epoch 26/30\n",
      "131/131 [==============================] - 3s 22ms/step - loss: 0.2348 - acc: 0.9281 - val_loss: 0.1809 - val_acc: 0.9391\n",
      "Epoch 27/30\n",
      "131/131 [==============================] - 3s 22ms/step - loss: 0.2312 - acc: 0.9293 - val_loss: 0.1813 - val_acc: 0.9402\n",
      "Epoch 28/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2337 - acc: 0.9300 - val_loss: 0.1792 - val_acc: 0.9423\n",
      "Epoch 29/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2243 - acc: 0.9294 - val_loss: 0.1797 - val_acc: 0.9412\n",
      "Epoch 30/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2286 - acc: 0.9285 - val_loss: 0.1794 - val_acc: 0.9402\n",
      "CNN 4: Epochs=30, Train accuracy=0.92990, Validation accuracy=0.94231\n",
      "Net : 5\n",
      "Epoch 1/30\n",
      "131/131 [==============================] - 6s 46ms/step - loss: 1.0589 - acc: 0.6793 - val_loss: 0.4087 - val_acc: 0.8803\n",
      "Epoch 2/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.6052 - acc: 0.8196 - val_loss: 0.4475 - val_acc: 0.8568\n",
      "Epoch 3/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.4816 - acc: 0.8568 - val_loss: 0.3041 - val_acc: 0.9188\n",
      "Epoch 4/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.4257 - acc: 0.8726 - val_loss: 0.2845 - val_acc: 0.9241\n",
      "Epoch 5/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3946 - acc: 0.8849 - val_loss: 0.2689 - val_acc: 0.9241\n",
      "Epoch 6/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.3637 - acc: 0.8926 - val_loss: 0.2699 - val_acc: 0.9209\n",
      "Epoch 7/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.3425 - acc: 0.8980 - val_loss: 0.2560 - val_acc: 0.9306\n",
      "Epoch 8/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3276 - acc: 0.8994 - val_loss: 0.2473 - val_acc: 0.9252\n",
      "Epoch 9/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3267 - acc: 0.9028 - val_loss: 0.2276 - val_acc: 0.9306\n",
      "Epoch 10/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.3172 - acc: 0.9022 - val_loss: 0.2246 - val_acc: 0.9348\n",
      "Epoch 11/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.3018 - acc: 0.9086 - val_loss: 0.2363 - val_acc: 0.9359\n",
      "Epoch 12/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2892 - acc: 0.9122 - val_loss: 0.2118 - val_acc: 0.9391\n",
      "Epoch 13/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2845 - acc: 0.9142 - val_loss: 0.2100 - val_acc: 0.9391\n",
      "Epoch 14/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2707 - acc: 0.9181 - val_loss: 0.2201 - val_acc: 0.9252\n",
      "Epoch 15/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2697 - acc: 0.9182 - val_loss: 0.2168 - val_acc: 0.9316\n",
      "Epoch 16/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2426 - acc: 0.9249 - val_loss: 0.1947 - val_acc: 0.9402\n",
      "Epoch 17/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2559 - acc: 0.9242 - val_loss: 0.2069 - val_acc: 0.9295\n",
      "Epoch 18/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2415 - acc: 0.9252 - val_loss: 0.2053 - val_acc: 0.9348\n",
      "Epoch 19/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2451 - acc: 0.9265 - val_loss: 0.2016 - val_acc: 0.9359\n",
      "Epoch 20/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2433 - acc: 0.9272 - val_loss: 0.1990 - val_acc: 0.9402\n",
      "Epoch 21/30\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.2283 - acc: 0.9306 - val_loss: 0.1948 - val_acc: 0.9423\n",
      "Epoch 22/30\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.2341 - acc: 0.9279 - val_loss: 0.1988 - val_acc: 0.9402\n",
      "Epoch 23/30\n",
      "131/131 [==============================] - 3s 19ms/step - loss: 0.2208 - acc: 0.9318 - val_loss: 0.1976 - val_acc: 0.9391\n",
      "Epoch 24/30\n",
      "131/131 [==============================] - 3s 22ms/step - loss: 0.2240 - acc: 0.9326 - val_loss: 0.1885 - val_acc: 0.9423\n",
      "Epoch 25/30\n",
      "131/131 [==============================] - 3s 22ms/step - loss: 0.2237 - acc: 0.9316 - val_loss: 0.1911 - val_acc: 0.9423\n",
      "Epoch 26/30\n",
      " 98/131 [=====================>........] - ETA: 0s - loss: 0.2313 - acc: 0.9306"
     ]
    }
   ],
   "source": [
    "\n",
    "history = [0] * nets\n",
    "epochs = 30\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=13,\n",
    "    zoom_range=0.11,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "for j in range(nets):\n",
    "    print(f'Net : {j+1}')   \n",
    "    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size = 0.1)\n",
    "    history[j] = model[j].fit_generator(datagen.flow(X_train2,Y_train2, batch_size=64),\n",
    "        epochs = epochs, steps_per_epoch = X_train2.shape[0]//64,  \n",
    "        validation_data = (X_val2,Y_val2), callbacks=[learning_rate_reduction], verbose=1)\n",
    "    \n",
    "    print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n",
    "        j+1,epochs,max(history[j].history['acc']),max(history[j].history['val_acc']) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "96d0aa4b067758d1f5ca5b4e74c9f3f4095e7cb3"
   },
   "outputs": [],
   "source": [
    "# make submision\n",
    "results = np.zeros( (X_test.shape[0],10) ) \n",
    "for j in range(nets):\n",
    "    results = results + model[j].predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "4700ec41a1368c707e671d58638a767a55ef302e"
   },
   "outputs": [],
   "source": [
    "    \n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"target\")\n",
    "submission = pd.concat([pd.Series(range(0,9364),name = \"Id\"),results],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "aaeded284cfc08c889d2c4a5519a199ad99470b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  target\n",
       "0   0       0\n",
       "1   1       7\n",
       "2   2       0\n",
       "3   3       0\n",
       "4   4       7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "ff01d9adbf13f93a32c2cb284cc2e2c830db0bcb"
   },
   "outputs": [],
   "source": [
    "submission['target'] = enc.inverse_transform(submission['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "67bd036b6b39c2006566ee5e91a3c9d641b56d60"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id target\n",
       "0   0      A\n",
       "1   1      H\n",
       "2   2      A\n",
       "3   3      A\n",
       "4   4      H"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "b87a43688a7beac4f4d528f31a57cb5000e3aa9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9364, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "3946740c3931d357362b4784fe55136cae18dd12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D    977\n",
       "J    971\n",
       "G    954\n",
       "H    949\n",
       "E    941\n",
       "B    933\n",
       "F    932\n",
       "C    914\n",
       "A    912\n",
       "I    881\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "75f06975a1531ae3009f534648fb854f964232fc"
   },
   "outputs": [],
   "source": [
    "submission.to_csv('sub_ensemble_10_cnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "9daefa41bf7024246734fe11fea67e4ffc8efaf9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
